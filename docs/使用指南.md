# Paddle Format 使用指南

## 概述

本工具提供了完整的数据集处理功能，支持VOC到COCO/YOLO格式转换、数据验证、清洗、类别筛选、数据集划分等。支持多线程并发处理，大幅提升处理效率。

## 支持的格式转换

### 1. VOC → COCO (PaddleDetection)
- 适用于百度飞桨PaddleDetection框架
- 生成标准COCO格式JSON文件
- 支持训练集/验证集/测试集划分

### 2. VOC → YOLO (YOLOv6-YOLOv13)
- 适用于YOLO系列模型训练
- 生成归一化坐标格式标注
- 自动生成YAML配置文件

## 快速开始

### 1. 简单一键处理

最简单的使用方式是使用一键处理功能：

```python
from code.dataset_handler.voc_dataset import VOCDataset

# 初始化数据集
dataset = VOCDataset(
    dataset_path="dataset/Fruit",  # 数据集路径
    train_ratio=0.8,               # 训练集比例
    val_ratio=0.2,                 # 验证集比例
    test_ratio=0.0,                # 测试集比例
    max_workers=4                  # 线程池大小
)

# 一键完成所有处理
dataset.one_click_complete_conversion()
```

### 2. 类别筛选处理

支持两种类别筛选模式：

#### 排除不想要的类别
```python
# 排除指定类别
exclude_labels = ['banana', 'dragon fruit']
dataset.one_click_complete_conversion(exclude_labels=exclude_labels)
```

#### 只保留指定类别
```python
# 只保留指定类别
include_labels = ['pineapple', 'snake fruit']
dataset.one_click_complete_conversion(include_labels=include_labels)
```

## 使用示例

### 示例1：VOC到COCO格式转换（code/use_code/simple_process_example.py）

### 示例2：VOC到YOLO格式转换（code/use_code/yolo_conversion_example.py）

```python
from code.dataset_handler.yolo_series_dataset import YOLOSeriesDataset

# 初始化YOLO数据集处理器
yolo_dataset = YOLOSeriesDataset(
    dataset_path="dataset/Fruit",
    train_ratio=0.8,
    val_ratio=0.2,
    test_ratio=0.0
)

# 转换所有类别
yolo_dataset.one_click_complete_conversion()

# 或者只保留指定类别
target_labels = ['pineapple', 'snake fruit']
yolo_dataset.one_click_complete_conversion(include_labels=target_labels)
```

### 示例3：标签过滤处理（code/use_code/label_filtering_example.py）

这是最基础的使用示例，展示如何进行一键数据处理：

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
简单的一键清洗+转换示例
使用dataset/Fruit数据集进行演示
"""

import os
import sys

# 添加项目根目录到Python路径
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from code.dataset_handler.voc_dataset import VOCDataset

def main():
    """简单的一键处理示例"""
    
    # 数据集路径
    dataset_path = os.path.join(project_root, "dataset", "Fruit")
    
    print("🚀 开始简单的一键清洗+转换处理...")
    print("=" * 60)
    print(f"📁 数据集路径: {dataset_path}")
    print()
    
    try:
        # 初始化数据集处理器
        print("🔧 初始化数据集处理器...")
        dataset = VOCDataset(
            dataset_path=dataset_path,
            train_ratio=0.8,      # 训练集比例
            val_ratio=0.1,        # 验证集比例
            test_ratio=0.1,       # 测试集比例
            max_workers=4         # 线程池大小
        )
        
        print("✅ 数据集初始化完成")
        print()
        
        # 一键完成所有处理
        print("🚀 开始一键完整转换...")
        result = dataset.one_click_complete_conversion()
        
        if result.get("success", False):
            print("🎉 处理完成！")
            print("=" * 60)
            print("📋 处理结果:")
            print(f"   - 清洗后的XML文件: {os.path.join(dataset_path, 'Annotations_clear')}")
            print(f"   - 数据集划分文件: {os.path.join(dataset_path, 'ImageSets', 'Main')}")
            print(f"   - COCO格式文件: {dataset_path}")
            print("     * train_coco.json")
            print("     * val_coco.json")
            if dataset.test_ratio > 0:
                print("     * test_coco.json")
        else:
            print(f"❌ 处理失败: {result.get('message', '未知错误')}")
            
    except Exception as e:
        print(f"❌ 处理过程中出现错误: {str(e)}")

if __name__ == "__main__":
    main()
```

**重要提示**: 确保 `train_ratio + val_ratio + test_ratio = 1.0`，当 `test_ratio > 0` 时会自动生成 `test.txt` 和 `test_coco.json` 文件。

### 示例2：类别筛选处理（code/use_code/label_filtering_example.py）

这个示例展示如何使用类别筛选功能，支持两种筛选模式：

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
标签过滤功能演示
演示如何使用include_labels和exclude_labels参数进行类别筛选
"""

import os
import sys

# 添加项目根目录到Python路径
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from code.dataset_handler.voc_dataset import VOCDataset

def main():
    """标签过滤功能演示"""
    
    # 数据集路径
    dataset_path = os.path.join(project_root, "dataset", "Fruit")
    
    print("🏷️  标签过滤功能演示")
    print("=" * 60)
    print(f"📁 数据集路径: {dataset_path}")
    print()
    
    # 让用户选择筛选方式
    print("请选择筛选方式:")
    print("1. 只保留指定类别 (include_labels)")
    print("2. 排除指定类别 (exclude_labels)")
    
    choice = input("请输入选择 (1 或 2): ").strip()
    
    # 指定要处理的类别
    target_labels = ['pineapple', 'snake fruit']
    
    if choice == '1':
        # 方式1：只保留指定类别
        dataset = VOCDataset(
            dataset_path=dataset_path,
            train_ratio=0.8,
            val_ratio=0.2,
            test_ratio=0.0,
            max_workers=4,
            include_labels=target_labels  # 只保留指定类别
        )
        
        print(f"✅ 只保留 {target_labels} 类别")
        result = dataset.one_click_complete_conversion()
        
    elif choice == '2':
        # 方式2：排除指定类别
        dataset = VOCDataset(
            dataset_path=dataset_path,
            train_ratio=0.8,
            val_ratio=0.2,
            test_ratio=0.0,
            max_workers=4,
            exclude_labels=target_labels  # 排除指定类别
        )
        
        print(f"✅ 排除 {target_labels} 类别")
        result = dataset.one_click_complete_conversion()
    
    else:
        print("❌ 无效选择，请输入 1 或 2")
        return
    
    # 验证处理结果
    if result.get("success", False):
        annotations_clear_dir = os.path.join(dataset_path, "Annotations_clear")
        if os.path.exists(annotations_clear_dir):
            xml_files = [f for f in os.listdir(annotations_clear_dir) if f.endswith('.xml')]
            print(f"📁 清洗后的XML文件数量: {len(xml_files)} 个")
            print(f"📂 清洗输出目录: {annotations_clear_dir}")

if __name__ == "__main__":
    main()
```

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
简单的一键清洗+转换使用示例
使用dataset/Fruit数据集演示完整的数据处理流程
"""

import os
import sys

# 添加项目根目录到Python路径
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from code.dataset_handler.voc_dataset import VOCDataset

def main():
    """简单的一键处理示例"""
    print("🚀 开始简单的一键清洗+转换处理...")
    
    # 设置数据集路径
    dataset_path = os.path.join(project_root, "dataset", "Fruit")
    
    # 初始化VOC数据集处理器
    dataset = VOCDataset(
        dataset_path=dataset_path,
        train_ratio=0.8,      # 训练集比例
        val_ratio=0.2,        # 验证集比例
        test_ratio=0.0,       # 测试集比例
        max_workers=4         # 线程池大小
    )
    
    # 执行一键完整转换
    dataset.one_click_complete_conversion(skip_confirmation=True)
    
    print("🎉 处理完成！")

if __name__ == "__main__":
    main()
```

### 示例2：类别筛选（code/use_code/label_filtering_example.py）

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
类别筛选使用示例
演示如何筛选掉不想要的类，或者指定想要的类
"""

from code.dataset_handler.voc_dataset import VOCDataset

def example_exclude_labels():
    """示例1: 排除不想要的类别"""
    dataset = VOCDataset(dataset_path="dataset/Fruit")
    
    # 排除不想要的类别
    exclude_labels = ['banana', 'dragon fruit']
    dataset.one_click_complete_conversion(
        exclude_labels=exclude_labels,
        skip_confirmation=True
    )

def example_include_labels():
    """示例2: 只保留指定的类别"""
    dataset = VOCDataset(dataset_path="dataset/Fruit")
    
    # 只保留指定的类别
    include_labels = ['pineapple', 'snake fruit']
    dataset.one_click_complete_conversion(
        include_labels=include_labels,
        skip_confirmation=True
    )

if __name__ == "__main__":
    # 运行示例
    example_include_labels()
```

## 核心功能详解

### 1. 数据集初始化

```python
dataset = VOCDataset(
    dataset_path="path/to/dataset",     # 数据集路径（必需）
    train_ratio=0.85,                   # 训练集比例（默认0.85）
    val_ratio=0.15,                     # 验证集比例（默认0.15）
    test_ratio=0.0,                     # 测试集比例（默认0.0）
    max_workers=4,                      # 线程池大小（默认4）
    exclude_labels=None,                # 排除的类别列表
    include_labels=None,                # 包含的类别列表
    output_annotations_name=None        # 输出标注文件夹名称
)
```

### 2. 一键处理功能

`one_click_complete_conversion()` 方法包含以下步骤：

1. **数据验证和清洗**
   - 验证数据集基本结构
   - 并行匹配图像和标注文件
   - 清理空标注文件
   - 类别筛选（如果指定）

2. **图像尺寸检查和修正**
   - 并行检查图像尺寸一致性
   - 自动修正XML中的尺寸信息
   - 转换图像格式（如需要）

3. **数据集划分**
   - 按指定比例划分训练/验证/测试集
   - 生成划分文件（train.txt, val.txt, test.txt, trainval.txt）

4. **COCO格式转换**
   - 转换为COCO格式JSON文件
   - 支持Paddle3新格式要求
   - 包含info和licenses字段

### 3. 类别筛选功能

#### 排除模式（exclude_labels）
```python
# 排除不想要的类别
exclude_labels = ['class1', 'class2']
dataset.one_click_complete_conversion(exclude_labels=exclude_labels)
```

#### 包含模式（include_labels）
```python
# 只保留指定类别
include_labels = ['class3', 'class4']
dataset.one_click_complete_conversion(include_labels=include_labels)
```

**注意**：exclude_labels 和 include_labels 不能同时使用。

### 4. 输出结果

处理完成后，会在数据集目录下生成：

```
dataset/
├── Annotations/              # 原始标注文件
├── Annotations_clear/        # 清洗后的标注文件
├── JPEGImages/              # 图像文件
├── ImageSets/
│   └── Main/
│       ├── train.txt        # 训练集文件列表
│       ├── val.txt          # 验证集文件列表
│       ├── test.txt         # 测试集文件列表
│       ├── trainval.txt     # 训练+验证集文件列表
│       └── labels.txt       # 类别标签文件
├── train_coco.json          # 训练集COCO格式
└── val_coco.json            # 验证集COCO格式
```

## 高级功能

### 1. 多线程并发处理

工具使用线程池实现并发处理，大幅提升处理效率：

```python
# 设置更多工作线程
dataset = VOCDataset(
    dataset_path="path/to/dataset",
    max_workers=8  # 增加线程数
)
```

### 2. XML格式保持

处理过程中完全保持XML文件的原始格式（缩进、换行等）。

### 3. 独立输出目录

清洗后的文件保存到独立目录，保护原始数据不被修改。

### 4. 自动数据集名称获取

从数据集路径自动获取数据集名称，无需手动指定。

## 错误处理

工具包含完善的错误处理机制：

- 自动检测和修复图像尺寸不匹配
- 处理损坏的XML文件
- 验证文件完整性
- 详细的日志记录

## 性能优化

- 多线程并发处理XML文件
- 批量文件操作
- 内存优化的大文件处理
- 进度条显示处理状态

## 注意事项

1. **数据备份**：处理前请备份原始数据集
2. **路径格式**：使用正斜杠或反斜杠都可以，工具会自动处理
3. **内存使用**：大数据集处理时注意内存使用情况
4. **线程数量**：根据CPU核心数合理设置线程池大小

## 常见问题

### Q: 如何处理大型数据集？
A: 增加线程池大小，使用批处理模式：
```python
dataset = VOCDataset(dataset_path="path", max_workers=8)
```

### Q: 如何只处理特定类别？
A: 使用include_labels参数：
```python
dataset.one_click_complete_conversion(include_labels=['cat', 'dog'])
```

### Q: 处理后的文件在哪里？
A: 清洗后的XML文件在 `Annotations_clear` 目录，COCO文件在数据集根目录。

### Q: 如何跳过用户确认？
A: 使用skip_confirmation参数：
```python
dataset.one_click_complete_conversion(skip_confirmation=True)