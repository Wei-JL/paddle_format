# VOC数据集处理工具使用指南

## 概述

本工具提供了完整的VOC格式数据集处理功能，包括数据验证、清洗、类别筛选、数据集划分和格式转换等。支持多线程并发处理，大幅提升处理效率。

## 快速开始

### 1. 简单一键处理

最简单的使用方式是使用一键处理功能：

```python
from code.dataset_handler.voc_dataset import VOCDataset

# 初始化数据集
dataset = VOCDataset(
    dataset_path="dataset/Fruit",  # 数据集路径
    train_ratio=0.8,               # 训练集比例
    val_ratio=0.2,                 # 验证集比例
    test_ratio=0.0,                # 测试集比例
    max_workers=4                  # 线程池大小
)

# 一键完成所有处理
dataset.one_click_complete_conversion()
```

### 2. 类别筛选处理

支持两种类别筛选模式：

#### 排除不想要的类别
```python
# 排除指定类别
exclude_labels = ['banana', 'dragon fruit']
dataset.one_click_complete_conversion(exclude_labels=exclude_labels)
```

#### 只保留指定类别
```python
# 只保留指定类别
include_labels = ['pineapple', 'snake fruit']
dataset.one_click_complete_conversion(include_labels=include_labels)
```

## 使用示例

### 示例1：简单处理（code/use_code/simple_process_example.py）

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
简单的一键清洗+转换使用示例
使用dataset/Fruit数据集演示完整的数据处理流程
"""

import os
import sys

# 添加项目根目录到Python路径
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from code.dataset_handler.voc_dataset import VOCDataset

def main():
    """简单的一键处理示例"""
    print("🚀 开始简单的一键清洗+转换处理...")
    
    # 设置数据集路径
    dataset_path = os.path.join(project_root, "dataset", "Fruit")
    
    # 初始化VOC数据集处理器
    dataset = VOCDataset(
        dataset_path=dataset_path,
        train_ratio=0.8,      # 训练集比例
        val_ratio=0.2,        # 验证集比例
        test_ratio=0.0,       # 测试集比例
        max_workers=4         # 线程池大小
    )
    
    # 执行一键完整转换
    dataset.one_click_complete_conversion(skip_confirmation=True)
    
    print("🎉 处理完成！")

if __name__ == "__main__":
    main()
```

### 示例2：类别筛选（code/use_code/label_filtering_example.py）

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
类别筛选使用示例
演示如何筛选掉不想要的类，或者指定想要的类
"""

from code.dataset_handler.voc_dataset import VOCDataset

def example_exclude_labels():
    """示例1: 排除不想要的类别"""
    dataset = VOCDataset(dataset_path="dataset/Fruit")
    
    # 排除不想要的类别
    exclude_labels = ['banana', 'dragon fruit']
    dataset.one_click_complete_conversion(
        exclude_labels=exclude_labels,
        skip_confirmation=True
    )

def example_include_labels():
    """示例2: 只保留指定的类别"""
    dataset = VOCDataset(dataset_path="dataset/Fruit")
    
    # 只保留指定的类别
    include_labels = ['pineapple', 'snake fruit']
    dataset.one_click_complete_conversion(
        include_labels=include_labels,
        skip_confirmation=True
    )

if __name__ == "__main__":
    # 运行示例
    example_include_labels()
```

## 核心功能详解

### 1. 数据集初始化

```python
dataset = VOCDataset(
    dataset_path="path/to/dataset",     # 数据集路径（必需）
    train_ratio=0.85,                   # 训练集比例（默认0.85）
    val_ratio=0.15,                     # 验证集比例（默认0.15）
    test_ratio=0.0,                     # 测试集比例（默认0.0）
    max_workers=4,                      # 线程池大小（默认4）
    exclude_labels=None,                # 排除的类别列表
    include_labels=None,                # 包含的类别列表
    output_annotations_name=None        # 输出标注文件夹名称
)
```

### 2. 一键处理功能

`one_click_complete_conversion()` 方法包含以下步骤：

1. **数据验证和清洗**
   - 验证数据集基本结构
   - 并行匹配图像和标注文件
   - 清理空标注文件
   - 类别筛选（如果指定）

2. **图像尺寸检查和修正**
   - 并行检查图像尺寸一致性
   - 自动修正XML中的尺寸信息
   - 转换图像格式（如需要）

3. **数据集划分**
   - 按指定比例划分训练/验证/测试集
   - 生成划分文件（train.txt, val.txt, test.txt, trainval.txt）

4. **COCO格式转换**
   - 转换为COCO格式JSON文件
   - 支持Paddle3新格式要求
   - 包含info和licenses字段

### 3. 类别筛选功能

#### 排除模式（exclude_labels）
```python
# 排除不想要的类别
exclude_labels = ['class1', 'class2']
dataset.one_click_complete_conversion(exclude_labels=exclude_labels)
```

#### 包含模式（include_labels）
```python
# 只保留指定类别
include_labels = ['class3', 'class4']
dataset.one_click_complete_conversion(include_labels=include_labels)
```

**注意**：exclude_labels 和 include_labels 不能同时使用。

### 4. 输出结果

处理完成后，会在数据集目录下生成：

```
dataset/
├── Annotations/              # 原始标注文件
├── Annotations_clear/        # 清洗后的标注文件
├── JPEGImages/              # 图像文件
├── ImageSets/
│   └── Main/
│       ├── train.txt        # 训练集文件列表
│       ├── val.txt          # 验证集文件列表
│       ├── test.txt         # 测试集文件列表
│       ├── trainval.txt     # 训练+验证集文件列表
│       └── labels.txt       # 类别标签文件
├── train_coco.json          # 训练集COCO格式
└── val_coco.json            # 验证集COCO格式
```

## 高级功能

### 1. 多线程并发处理

工具使用线程池实现并发处理，大幅提升处理效率：

```python
# 设置更多工作线程
dataset = VOCDataset(
    dataset_path="path/to/dataset",
    max_workers=8  # 增加线程数
)
```

### 2. XML格式保持

处理过程中完全保持XML文件的原始格式（缩进、换行等）。

### 3. 独立输出目录

清洗后的文件保存到独立目录，保护原始数据不被修改。

### 4. 自动数据集名称获取

从数据集路径自动获取数据集名称，无需手动指定。

## 错误处理

工具包含完善的错误处理机制：

- 自动检测和修复图像尺寸不匹配
- 处理损坏的XML文件
- 验证文件完整性
- 详细的日志记录

## 性能优化

- 多线程并发处理XML文件
- 批量文件操作
- 内存优化的大文件处理
- 进度条显示处理状态

## 注意事项

1. **数据备份**：处理前请备份原始数据集
2. **路径格式**：使用正斜杠或反斜杠都可以，工具会自动处理
3. **内存使用**：大数据集处理时注意内存使用情况
4. **线程数量**：根据CPU核心数合理设置线程池大小

## 常见问题

### Q: 如何处理大型数据集？
A: 增加线程池大小，使用批处理模式：
```python
dataset = VOCDataset(dataset_path="path", max_workers=8)
```

### Q: 如何只处理特定类别？
A: 使用include_labels参数：
```python
dataset.one_click_complete_conversion(include_labels=['cat', 'dog'])
```

### Q: 处理后的文件在哪里？
A: 清洗后的XML文件在 `Annotations_clear` 目录，COCO文件在数据集根目录。

### Q: 如何跳过用户确认？
A: 使用skip_confirmation参数：
```python
dataset.one_click_complete_conversion(skip_confirmation=True)