# 项目文件树文档

## 项目整体结构

```
paddle_format/
├── code/                           # 核心代码目录
│   ├── dataset_handler/            # 数据集处理模块
│   │   ├── __init__.py
│   │   ├── voc_dataset.py         # VOC数据集核心处理类
│   │   └── coco_dataset.py        # COCO数据集处理类
│   ├── global_var/                # 全局变量模块
│   │   ├── __init__.py
│   │   └── global_cls.py          # 全局变量和常量定义
│   ├── logger_code/               # 日志模块
│   │   ├── __init__.py
│   │   └── logger_config.py       # 日志配置
│   ├── use_code/                           # 使用示例代码
│   │   ├── simple_process_example.py       # 简单一键清洗+转换示例
│   │   └── label_filtering_example.py      # 类别筛选使用示例
│   └── logs/                      # 代码级日志目录
├── dataset/                       # 示例数据集目录
│   └── Fruit/                     # 示例水果数据集
├── docs/                         # 文档目录
│   ├── 使用指南.md               # 详细使用指南
│   └── 文件树文档.md             # 本文档
├── logs/                         # 全局系统日志目录
├── output/                       # 输出文件目录
└── .gitignore                   # Git忽略配置
```

## 核心模块详解

### 1. `dataset_handler` 模块

#### `voc_dataset.py` - 核心数据集处理类
这是整个工具的核心，封装了所有与VOC数据集处理相关的功能。

**核心类 `VOCDataset`**:
```python
class VOCDataset:
    def __init__(self, dataset_path, train_ratio=0.85, val_ratio=0.15, test_ratio=0.0, 
                 user_labels_file=None, max_workers=4, annotations_folder_name="Annotations",
                 exclude_labels=None, include_labels=None, output_annotations_name=None)
```
**主要方法**:
- `one_click_complete_conversion()`: **(推荐)** 一键完成从验证、清洗、过滤到格式转换的所有步骤。
- `validate_dataset()`: 验证数据集的完整性和基本结构。
- `clean_dataset()`: 清洗无效的或空的标注文件。
- `split_dataset()`: 将数据集划分为训练、验证和测试集。
- `convert_to_coco_format()`: 将VOC格式的标注转换为COCO格式。
- `count_and_sort_classes()`: 统计并排序数据集中的所有类别。

#### `coco_dataset.py` - COCO数据集处理类
提供COCO格式数据集的处理功能。

### 2. `global_var` 模块

#### `global_cls.py` - 全局变量定义
定义了项目中使用的常量，如支持的图像格式、默认文件夹名称等，便于统一管理和修改。

### 3. `use_code` 模块 - 测试和示例代码
包含了多个测试脚本，用于验证核心功能的正确性，并提供了如何使用 `VOCDataset` 类的示例。
- `test_label_filter.py`: 演示如何使用 `include_labels` 和 `exclude_labels` 参数进行标签过滤。
- `test_birdnest_processing.py`: 一个针对特定数据集（BirdNest）进行处理的实际案例。

## 标签过滤功能详解 (v2.1 新增)

### 功能概述
`VOCDataset` 类新增了强大的标签过滤功能，它允许用户在处理数据集时，通过 `exclude_labels` (排除标签) 或 `include_labels` (仅保留标签) 参数来精确控制需要处理的类别。

### 核心特性
1.  **线程池并发处理**: 利用 `ThreadPoolExecutor` 实现多线程并行处理XML文件，极大地提升了处理效率，尤其是在面对包含数万个文件的大型数据集时。
2.  **XML格式保持**: 在对XML文件进行读写和修改时，采用 `minidom` 库来确保原始文件的缩进、换行等格式被完整保留。
3.  **独立输出目录**: 经过标签过滤后的新标注文件将被保存到一个独立的、用户可指定的文件夹中（例如 `Annotations_filtered`），从而确保原始 `Annotations` 文件夹不受任何影响。
4.  **空文件自动处理**: 如果一个XML文件中的所有目标对象（object）都在过滤过程中被移除，该文件将不会被保存到输出目录，避免了生成无用的空标注文件。

### 使用场景
- **数据集清洗**: 快速移除数据集中标注错误或不再需要的类别。
- **子集训练**: 从一个大的数据集中提取出特定的几个类别，用于训练专门的模型。
- **数据对齐**: 在合并多个来源不同的数据集时，统一它们的标签集合。

## 版本更新记录

### v2.2.1 (当前版本)
- **简化标签过滤示例**: 优化 `label_filtering_example.py`，提供更直观的用户交互
- **修复测试集生成**: 解决 `test_ratio > 0` 时不生成 `test_coco.json` 的问题
- **完善数据集划分**: 确保训练集、验证集、测试集比例验证正确
- **优化用户体验**: 简化示例代码，提供清晰的选择界面

### v2.2.0
- **新增简化示例**: 添加 `simple_process_example.py` 一键处理示例
- **修复类别筛选**: 完善 `include_labels` 和 `exclude_labels` 功能
- **支持测试集**: 完整支持三分割数据集（训练/验证/测试）
- **文档完善**: 更新所有相关文档和项目结构说明

### v2.1
- **新增标签过滤功能**: 支持 `exclude_labels` 和 `include_labels` 两种模式。
- **引入并发处理**: 使用线程池大幅提升XML文件处理效率。
- **保持XML格式**: 确保在修改后XML文件的原始格式不变。
- **新增独立输出目录**: 过滤后的文件将保存到新目录，保护原始数据。
- **动态数据集名称**: 从输入路径自动推断数据集名称。
- **路径标准化**: 所有文件路径操作均使用 `os.path.join`，增强了跨平台兼容性。
- **全局变量管理**: 将项目范围内的常量统一到 `global_cls.py` 中管理。

### v2.0
- 添加 `one_click_complete_conversion` 功能，整合所有处理步骤。
- 优化了COCO格式的输出逻辑。

### v1.0
- 实现基础的VOC数据集处理功能，包括分割和COCO转换。