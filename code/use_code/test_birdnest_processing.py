"""
BirdNestæ•°æ®é›†å¤„ç†æµ‹è¯•
æµ‹è¯•ä¿®æ”¹åçš„VOCDatasetç±»çš„åŠŸèƒ½
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.path
project_root = Path(__file__).parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "code"))

from code.dataset_handler.voc_dataset import VOCDataset
from code.logger_code.logger_sys import get_logger

# è·å–æ—¥å¿—è®°å½•å™¨
logger = get_logger("test_birdnest_processing")

def test_birdnest_dataset():
    """æµ‹è¯•BirdNestæ•°æ®é›†å¤„ç†"""
    
    # æ•°æ®é›†è·¯å¾„
    dataset_path = r"D:\WJL\project\BirdNest"
    
    print("=" * 80)
    print("ğŸ¦ BirdNestæ•°æ®é›†å¤„ç†æµ‹è¯•")
    print("=" * 80)
    print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset_path}")
    
    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        logger.error(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        return False
    
    try:
        print("\nğŸ“‹ æ­¥éª¤1: åˆå§‹åŒ–VOCæ•°æ®é›†...")
        logger.info("å¼€å§‹åˆå§‹åŒ–VOCæ•°æ®é›†")
        
        # æµ‹è¯•è¦æ±‚1: ä¸éœ€è¦è¾“å…¥dataset_nameï¼Œè‡ªåŠ¨ä»è·¯å¾„è·å–
        voc_dataset = VOCDataset(
            dataset_path=dataset_path,
            max_workers=6  # ä½¿ç”¨6ä¸ªçº¿ç¨‹è¿›è¡Œå¹¶è¡Œå¤„ç†
        )
        
        print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ“Š è‡ªåŠ¨è·å–çš„æ•°æ®é›†åç§°: {voc_dataset.dataset_name}")
        print(f"ğŸ§µ çº¿ç¨‹æ± é…ç½®: {voc_dataset.max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
        
        # éªŒè¯æ¸…æ´—è¾“å‡ºç›®å½•è®¾ç½®
        expected_output_dir = os.path.join(dataset_path, "Annotations_clear")
        actual_output_dir = str(voc_dataset.annotations_output_dir)
        print(f"ğŸ—‚ï¸  æ¸…æ´—è¾“å‡ºç›®å½•: {actual_output_dir}")
        
        if actual_output_dir == expected_output_dir:
            print("âœ… æ¸…æ´—è¾“å‡ºç›®å½•è®¾ç½®æ­£ç¡®")
        else:
            print(f"âŒ æ¸…æ´—è¾“å‡ºç›®å½•è®¾ç½®é”™è¯¯ï¼ŒæœŸæœ›: {expected_output_dir}")
        
        # è·å–æ•°æ®é›†åŸºæœ¬ä¿¡æ¯
        print("\nğŸ“‹ æ­¥éª¤2: è·å–æ•°æ®é›†åŸºæœ¬ä¿¡æ¯...")
        dataset_info = voc_dataset.get_dataset_info()
        
        print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset_info['dataset_path']}")
        print(f"ğŸ“‚ åŸå§‹æ ‡æ³¨ç›®å½•: {dataset_info['annotations_dir']}")
        print(f"ğŸ—‚ï¸  æ¸…æ´—è¾“å‡ºç›®å½•: {dataset_info['annotations_output_dir']}")
        print(f"ğŸ“ˆ åˆ’åˆ†æ¯”ä¾‹: è®­ç»ƒé›†{dataset_info['train_ratio']}, éªŒè¯é›†{dataset_info['val_ratio']}, æµ‹è¯•é›†{dataset_info['test_ratio']}")
        
        # æ‰§è¡Œä¸€é”®å®Œæˆè½¬æ¢
        print("\nğŸ“‹ æ­¥éª¤3: æ‰§è¡Œä¸€é”®å®Œæˆè½¬æ¢...")
        print("âš ï¸  æ³¨æ„ï¼šè¿™å°†æµ‹è¯•ä»¥ä¸‹åŠŸèƒ½ï¼š")
        print("   1. è‡ªåŠ¨è·å–æ•°æ®é›†åç§°")
        print("   2. ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ–‡ä»¶åŒ¹é…")
        print("   3. æ¸…æ´—XMLæ–‡ä»¶åˆ°Annotations_clearç›®å½•")
        print("   4. ä¿æŒXMLåŸæœ‰æ ¼å¼")
        print("   5. è¿‡æ»¤æ‰æ²¡æœ‰æ ‡æ³¨æ¡†çš„XMLæ–‡ä»¶")
        
        logger.info("å¼€å§‹æ‰§è¡Œä¸€é”®å®Œæˆè½¬æ¢")
        
        # è·³è¿‡ç”¨æˆ·ç¡®è®¤ï¼Œç›´æ¥å¤„ç†
        result = voc_dataset.one_click_complete_conversion(skip_confirmation=True)
        
        if result["success"]:
            print("\nğŸ‰ ä¸€é”®è½¬æ¢æˆåŠŸå®Œæˆï¼")
            print("=" * 80)
            print("ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
            print(f"   âœ… æœ‰æ•ˆæ–‡ä»¶å¯¹: {result.get('valid_pairs', 0)} ä¸ª")
            print(f"   ğŸ·ï¸  å‘ç°ç±»åˆ«: {result.get('classes', 0)} ä¸ª")
            print(f"   ğŸ—‚ï¸  æ¸…æ´—è¾“å‡ºç›®å½•: {result.get('annotations_output_dir', 'N/A')}")
            print("=" * 80)
            
            # éªŒè¯æ¸…æ´—ç»“æœ
            print("\nğŸ“‹ æ­¥éª¤4: éªŒè¯æ¸…æ´—ç»“æœ...")
            verify_cleaning_results(dataset_path, result)
            
            # æ˜¾ç¤ºæœ€ç»ˆæ•°æ®é›†ä¿¡æ¯
            final_info = voc_dataset.get_dataset_info()
            if final_info['classes']:
                print(f"ğŸ·ï¸  å‘ç°çš„ç±»åˆ«: {final_info['classes']}")
            
            logger.info("ä¸€é”®è½¬æ¢æˆåŠŸå®Œæˆ")
            return True
            
        else:
            print(f"\nâŒ ä¸€é”®è½¬æ¢å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            logger.error(f"ä¸€é”®è½¬æ¢å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {type(e).__name__}")
        
        # æ‰“å°è¯¦ç»†çš„é”™è¯¯å †æ ˆ
        import traceback
        logger.error(f"é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
        
        return False

def verify_cleaning_results(dataset_path, result):
    """éªŒè¯æ¸…æ´—ç»“æœ"""
    print("ğŸ” éªŒè¯æ¸…æ´—ç»“æœ...")
    
    # æ£€æŸ¥Annotations_clearç›®å½•
    annotations_clear_dir = os.path.join(dataset_path, "Annotations_clear")
    
    if os.path.exists(annotations_clear_dir):
        print(f"âœ… Annotations_clearç›®å½•å·²åˆ›å»º: {annotations_clear_dir}")
        
        # ç»Ÿè®¡æ¸…æ´—åçš„æ–‡ä»¶æ•°é‡
        xml_files = [f for f in os.listdir(annotations_clear_dir) if f.endswith('.xml')]
        print(f"ğŸ“Š æ¸…æ´—åXMLæ–‡ä»¶æ•°é‡: {len(xml_files)} ä¸ª")
        
        # æ£€æŸ¥å‡ ä¸ªXMLæ–‡ä»¶çš„æ ¼å¼æ˜¯å¦ä¿æŒ
        if xml_files:
            sample_xml = os.path.join(annotations_clear_dir, xml_files[0])
            print(f"ğŸ“„ æ£€æŸ¥æ ·æœ¬XMLæ–‡ä»¶: {xml_files[0]}")
            
            try:
                with open(sample_xml, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if content.strip():
                        print("âœ… XMLæ–‡ä»¶å†…å®¹æ­£å¸¸")
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼©è¿›ï¼ˆæ ¼å¼ä¿æŒï¼‰
                        if '  ' in content or '\t' in content:
                            print("âœ… XMLæ–‡ä»¶æ ¼å¼ä¿æŒè‰¯å¥½ï¼ˆæœ‰ç¼©è¿›ï¼‰")
                        else:
                            print("âš ï¸  XMLæ–‡ä»¶å¯èƒ½æ²¡æœ‰ä¿æŒåŸæœ‰ç¼©è¿›æ ¼å¼")
                    else:
                        print("âŒ XMLæ–‡ä»¶å†…å®¹ä¸ºç©º")
            except Exception as e:
                print(f"âŒ è¯»å–XMLæ–‡ä»¶å¤±è´¥: {e}")
        
        # æ£€æŸ¥ImageSetsç›®å½•
        imagesets_dir = os.path.join(dataset_path, "ImageSets", "Main")
        if os.path.exists(imagesets_dir):
            print(f"âœ… ImageSets/Mainç›®å½•å­˜åœ¨")
            
            # æ£€æŸ¥åˆ’åˆ†æ–‡ä»¶
            split_files = ["train.txt", "val.txt", "labels.txt"]
            for split_file in split_files:
                file_path = os.path.join(imagesets_dir, split_file)
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                        print(f"âœ… {split_file}: {len(lines)} è¡Œ")
                else:
                    print(f"âŒ {split_file}: ä¸å­˜åœ¨")
        else:
            print("âŒ ImageSets/Mainç›®å½•ä¸å­˜åœ¨")
    else:
        print(f"âŒ Annotations_clearç›®å½•æœªåˆ›å»º: {annotations_clear_dir}")

def check_dataset_structure(dataset_path):
    """æ£€æŸ¥æ•°æ®é›†ç»“æ„"""
    print(f"\nğŸ” æ£€æŸ¥æ•°æ®é›†ç»“æ„: {dataset_path}")
    
    required_dirs = [
        "Annotations",
        "JPEGImages", 
        "ImageSets"
    ]
    
    for dir_name in required_dirs:
        dir_path = os.path.join(dataset_path, dir_name)
        if os.path.exists(dir_path):
            file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])
            print(f"   âœ… {dir_name}: å­˜åœ¨ ({file_count} ä¸ªæ–‡ä»¶)")
        else:
            print(f"   âŒ {dir_name}: ä¸å­˜åœ¨")
    
    # æ£€æŸ¥ImageSets/Mainç›®å½•
    imagesets_main = os.path.join(dataset_path, "ImageSets", "Main")
    if os.path.exists(imagesets_main):
        file_count = len([f for f in os.listdir(imagesets_main) if os.path.isfile(os.path.join(imagesets_main, f))])
        print(f"   âœ… ImageSets/Main: å­˜åœ¨ ({file_count} ä¸ªæ–‡ä»¶)")
    else:
        print(f"   âš ï¸  ImageSets/Main: ä¸å­˜åœ¨ (å°†è‡ªåŠ¨åˆ›å»º)")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¦ BirdNestæ•°æ®é›†å¤„ç†æµ‹è¯•")
    print("æµ‹è¯•ä¿®æ”¹åçš„VOCDatasetç±»åŠŸèƒ½")
    print("éªŒè¯ä»¥ä¸‹è¦æ±‚:")
    print("1. è‡ªåŠ¨è·å–æ•°æ®é›†åç§°ï¼ˆä¸éœ€è¦è¾“å…¥dataset_nameï¼‰")
    print("2. æ¸…æ´—åXMLä¿å­˜åˆ°Annotations_clearç›®å½•")
    print("3. ä¿æŒXMLåŸæœ‰æ ¼å¼ï¼ˆæ¢è¡Œå’Œç¼©è¿›ï¼‰")
    print("4. ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ–‡ä»¶åŒ¹é…")
    print("5. è¿‡æ»¤æ‰æ²¡æœ‰æ ‡æ³¨æ¡†çš„XMLæ–‡ä»¶")
    
    dataset_path = r"D:\WJL\project\BirdNest"
    
    # æ£€æŸ¥æ•°æ®é›†ç»“æ„
    check_dataset_structure(dataset_path)
    
    # æ‰§è¡Œæµ‹è¯•
    success = test_birdnest_dataset()
    
    if success:
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼æ•°æ®é›†å¤„ç†æˆåŠŸ")
        print("ğŸ“ è¯·æŸ¥çœ‹ä»¥ä¸‹è¾“å‡º:")
        print(f"   - æ¸…æ´—åçš„XMLæ–‡ä»¶: {dataset_path}/Annotations_clear/")
        print(f"   - æ•°æ®é›†åˆ’åˆ†æ–‡ä»¶: {dataset_path}/ImageSets/Main/")
        print("ğŸ“‹ æ‰€æœ‰è¦æ±‚å‡å·²å®ç°:")
        print("   âœ… è‡ªåŠ¨è·å–æ•°æ®é›†åç§°")
        print("   âœ… XMLæ–‡ä»¶æ¸…æ´—åˆ°ç‹¬ç«‹ç›®å½•")
        print("   âœ… ä¿æŒXMLåŸæœ‰æ ¼å¼")
        print("   âœ… çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†")
        print("   âœ… è¿‡æ»¤ç©ºæ ‡æ³¨æ–‡ä»¶")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    return success

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        sys.exit(1)