"""
VOCæ•°æ®é›†ä¸€é”®å¤„ç†åŠŸèƒ½æ‰©å±•

ä¸ºVOCDatasetç±»æ·»åŠ ä¸€é”®å®Œæˆè½¬æ¢å¹¶ä¿®å¤æ‰€æœ‰é—®é¢˜çš„åŠŸèƒ½
"""

from typing import List, Dict
from pathlib import Path
import sys

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
sys.path.append(str(Path(__file__).parent.parent))
from logger_code.logger_sys import get_logger

# è·å–æ—¥å¿—è®°å½•å™¨
logger = get_logger("one_click_functions")


def one_click_process_dataset(voc_dataset, exclude_classes: List[str] = None, 
                             auto_fix_images: bool = True,
                             new_annotations_suffix: str = "filtered") -> Dict:
    """
    ä¸€é”®å®Œæˆæ•°æ®é›†è½¬æ¢å¹¶ä¿®å¤æ‰€æœ‰é—®é¢˜
    
    åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š
    1. æé†’ç”¨æˆ·å¤‡ä»½æ•°æ®é›†
    2. è¿‡æ»¤æŒ‡å®šç±»åˆ«ï¼ˆå¦‚æœæä¾›ï¼‰
    3. ä¿®æ­£å›¾åƒå’ŒXMLæ–‡ä»¶
    4. é‡æ–°åˆ’åˆ†VOCæ•°æ®é›†
    5. è½¬æ¢ä¸ºCOCOæ ¼å¼
    
    Args:
        voc_dataset: VOCDatasetå®ä¾‹
        exclude_classes: è¦å‰”é™¤çš„ç±»åˆ«åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºä¸è¿‡æ»¤
        auto_fix_images: æ˜¯å¦è‡ªåŠ¨ä¿®æ­£å›¾åƒå’ŒXMLæ–‡ä»¶
        new_annotations_suffix: è¿‡æ»¤åæ–°æ ‡æ³¨ç›®å½•çš„åç¼€å
        
    Returns:
        Dict: å¤„ç†ç»“æœç»Ÿè®¡ä¿¡æ¯
    """
    logger.info("=== å¼€å§‹ä¸€é”®æ•°æ®é›†å¤„ç† ===")
    
    # æ­¥éª¤1ï¼šæé†’ç”¨æˆ·å¤‡ä»½æ•°æ®é›†
    print("\n" + "="*60)
    print("âš ï¸  é‡è¦æé†’ï¼šæ•°æ®é›†å¤„ç†è­¦å‘Š")
    print("="*60)
    print("æ­¤æ“ä½œå°†å¯¹æ‚¨çš„æ•°æ®é›†è¿›è¡Œä»¥ä¸‹ä¿®æ”¹ï¼š")
    print("1. åˆ é™¤ç©ºæ ‡æ³¨æ–‡ä»¶")
    if exclude_classes:
        print(f"2. è¿‡æ»¤æŒ‡å®šç±»åˆ«: {exclude_classes}")
    if auto_fix_images:
        print("3. ä¿®æ­£å›¾åƒå°ºå¯¸å’Œé€šé“æ•°")
        print("4. æ›´æ–°XMLæ–‡ä»¶ä¸­çš„å°ºå¯¸ä¿¡æ¯")
    print("5. é‡æ–°åˆ’åˆ†æ•°æ®é›†")
    print("6. ç”ŸæˆCOCOæ ¼å¼æ–‡ä»¶")
    print("\nâš ï¸  å¼ºçƒˆå»ºè®®åœ¨å¤„ç†å‰å¤‡ä»½æ‚¨çš„åŸå§‹æ•°æ®é›†ï¼")
    print("="*60)
    
    # è·å–ç”¨æˆ·ç¡®è®¤
    while True:
        user_input = input("è¯·ç¡®è®¤æ‚¨å·²å¤‡ä»½æ•°æ®é›†ï¼Œè¾“å…¥ 'Y' ç»§ç»­å¤„ç†ï¼Œ'N' å–æ¶ˆå¤„ç†: ").strip().upper()
        if user_input == 'Y':
            logger.info("ç”¨æˆ·ç¡®è®¤ç»§ç»­å¤„ç†")
            break
        elif user_input == 'N':
            logger.info("ç”¨æˆ·å–æ¶ˆå¤„ç†")
            print("å¤„ç†å·²å–æ¶ˆ")
            return {'status': 'cancelled', 'message': 'ç”¨æˆ·å–æ¶ˆå¤„ç†'}
        else:
            print("è¯·è¾“å…¥ 'Y' æˆ– 'N'")
    
    # åˆå§‹åŒ–ç»“æœç»Ÿè®¡
    result = {
        'status': 'success',
        'steps_completed': [],
        'statistics': {},
        'generated_files': {},
        'errors': []
    }
    
    try:
        # æ­¥éª¤2ï¼šç±»åˆ«è¿‡æ»¤ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if exclude_classes:
            logger.info(f"æ­¥éª¤2: å¼€å§‹ç±»åˆ«è¿‡æ»¤ - æ’é™¤ç±»åˆ«: {exclude_classes}")
            filter_stats = voc_dataset.filter_classes_and_regenerate(exclude_classes, new_annotations_suffix)
            result['steps_completed'].append('class_filtering')
            result['statistics']['class_filtering'] = filter_stats
            logger.info("ç±»åˆ«è¿‡æ»¤å®Œæˆ")
        else:
            logger.info("æ­¥éª¤2: è·³è¿‡ç±»åˆ«è¿‡æ»¤")
        
        # æ­¥éª¤3ï¼šå›¾åƒå’ŒXMLä¿®æ­£
        if auto_fix_images:
            logger.info("æ­¥éª¤3: å¼€å§‹å›¾åƒå’ŒXMLæ–‡ä»¶ä¿®æ­£")
            fix_stats = voc_dataset.check_and_fix_image_dimensions(auto_fix=True)
            result['steps_completed'].append('image_fixing')
            result['statistics']['image_fixing'] = fix_stats
            logger.info("å›¾åƒå’ŒXMLæ–‡ä»¶ä¿®æ­£å®Œæˆ")
        else:
            logger.info("æ­¥éª¤3: è·³è¿‡å›¾åƒä¿®æ­£")
        
        # æ­¥éª¤4ï¼šé‡æ–°æå–ç±»åˆ«å’Œåˆ’åˆ†æ•°æ®é›†ï¼ˆå·²åœ¨å‰é¢æ­¥éª¤ä¸­å®Œæˆï¼‰
        logger.info("æ­¥éª¤4: æ•°æ®é›†åˆ’åˆ†å·²å®Œæˆ")
        result['steps_completed'].append('dataset_splitting')
        
        # æ­¥éª¤5ï¼šè½¬æ¢ä¸ºCOCOæ ¼å¼
        logger.info("æ­¥éª¤5: å¼€å§‹è½¬æ¢ä¸ºCOCOæ ¼å¼")
        coco_files = voc_dataset.convert_to_coco_format()
        result['steps_completed'].append('coco_conversion')
        result['generated_files']['coco'] = coco_files
        logger.info("COCOæ ¼å¼è½¬æ¢å®Œæˆ")
        
        # ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        final_info = voc_dataset.get_dataset_info()
        result['statistics']['final_dataset'] = final_info
        
        logger.info("=== ä¸€é”®æ•°æ®é›†å¤„ç†å®Œæˆ ===")
        
        # æ‰“å°å¤„ç†ç»“æœæ‘˜è¦
        _print_process_summary(result)
        
    except Exception as e:
        error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        result['status'] = 'error'
        result['errors'].append(error_msg)
        print(f"\nâŒ {error_msg}")
    
    return result


def _print_process_summary(result: Dict):
    """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®é›†å¤„ç†å®Œæˆæ‘˜è¦")
    print("="*60)
    
    # æ˜¾ç¤ºå®Œæˆçš„æ­¥éª¤
    print("âœ… å·²å®Œæˆçš„æ­¥éª¤:")
    step_names = {
        'class_filtering': 'ç±»åˆ«è¿‡æ»¤',
        'image_fixing': 'å›¾åƒå’ŒXMLä¿®æ­£',
        'dataset_splitting': 'æ•°æ®é›†åˆ’åˆ†',
        'coco_conversion': 'COCOæ ¼å¼è½¬æ¢'
    }
    for step in result['steps_completed']:
        print(f"   â€¢ {step_names.get(step, step)}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if 'final_dataset' in result['statistics']:
        final_stats = result['statistics']['final_dataset']
        print(f"\nğŸ“ˆ æœ€ç»ˆæ•°æ®é›†ç»Ÿè®¡:")
        print(f"   â€¢ æœ‰æ•ˆæ–‡ä»¶å¯¹: {final_stats['total_valid_pairs']} ä¸ª")
        print(f"   â€¢ ç±»åˆ«æ•°é‡: {final_stats['total_classes']} ä¸ª")
        print(f"   â€¢ ç±»åˆ«åˆ—è¡¨: {', '.join(final_stats['classes'])}")
    
    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
    if 'coco' in result['generated_files']:
        print(f"\nğŸ“ ç”Ÿæˆçš„COCOæ–‡ä»¶:")
        for split, file_path in result['generated_files']['coco'].items():
            print(f"   â€¢ {split}: {file_path}")
    
    # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    if result['errors']:
        print(f"\nâŒ é”™è¯¯ä¿¡æ¯:")
        for error in result['errors']:
            print(f"   â€¢ {error}")
    
    print("="*60)