"""
VOCæ•°æ®é›†å¤„ç†å™¨ - ä¼˜åŒ–ç‰ˆæœ¬
æ”¯æŒè‡ªå®šä¹‰æ ‡æ³¨æ–‡ä»¶å¤¹åç§°å’Œæ ‡ç­¾ç­›é€‰åŠŸèƒ½
"""

import os
import json
import shutil
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from tqdm import tqdm
import random

# å¯¼å…¥å…¨å±€å˜é‡å’Œæ—¥å¿—
from code.global_var.global_cls import *
from code.logger_code.my_logger import logger


class VOCDataset:
    """VOCæ•°æ®é›†å¤„ç†å™¨ - ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, dataset_path: str, user_labels_file: str = None, 
                 train_ratio: float = TRAIN_RATIO, 
                 val_ratio: float = VAL_RATIO, test_ratio: float = TEST_RATIO,
                 max_workers: int = 4, annotations_folder_name: str = ANNOTATIONS_DIR):
        """
        åˆå§‹åŒ–VOCæ•°æ®é›†
        
        Args:
            dataset_path: æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„
            user_labels_file: ç”¨æˆ·æä¾›çš„æ­£ç¡®æ ‡ç­¾æ–‡ä»¶è·¯å¾„
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
            test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
            max_workers: çº¿ç¨‹æ± æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
            annotations_folder_name: æ ‡æ³¨æ–‡ä»¶å¤¹åç§°ï¼Œé»˜è®¤ä¸º"Annotations"
        """
        self.dataset_path = Path(dataset_path)
        # è‡ªåŠ¨è·å–æ•°æ®é›†åç§°ï¼ˆæ–‡ä»¶å¤¹æœ€åä¸€ä¸ªåç§°ï¼‰
        self.dataset_name = self.dataset_path.name
        
        # æ ‡æ³¨æ–‡ä»¶å¤¹åç§°ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
        self.annotations_folder_name = annotations_folder_name
        
        # æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
        self.train_ratio = train_ratio
        self.val_ratio = val_ratio
        self.test_ratio = test_ratio
        
        # çº¿ç¨‹æ± é…ç½®
        self.max_workers = max_workers
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        self._lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
        
        # æ ‡å‡†VOCç›®å½•ç»“æ„ - ä½¿ç”¨os.path.joinæ‹¼æ¥è·¯å¾„
        self.annotations_dir = Path(os.path.join(str(self.dataset_path), self.annotations_folder_name))
        self.images_dir = Path(os.path.join(str(self.dataset_path), JPEGS_DIR))
        self.imagesets_dir = Path(os.path.join(str(self.dataset_path), IMAGESETS_DIR, MAIN_DIR))
        
        # æ¸…æ´—åçš„è¾“å‡ºç›®å½• - ä½¿ç”¨os.path.joinæ‹¼æ¥è·¯å¾„
        self.annotations_output_dir = Path(os.path.join(str(self.dataset_path), "Annotations_clear"))
        
        # ç”¨æˆ·æ ‡ç­¾æ–‡ä»¶
        self.user_labels_file = user_labels_file
        
        # æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        self.classes = set()
        self.class_counts = {}
        self.total_images = 0
        self.total_annotations = 0
        
        # æ—¥å¿—è®°å½•
        logger.info(f"åˆå§‹åŒ–VOCæ•°æ®é›†: {self.dataset_name}")
        logger.info(f"æ•°æ®é›†è·¯å¾„: {self.dataset_path}")
        logger.info(f"æ ‡æ³¨æ–‡ä»¶å¤¹: {self.annotations_folder_name}")
        logger.info(f"åˆ’åˆ†æ¯”ä¾‹ - è®­ç»ƒé›†: {self.train_ratio} éªŒè¯é›†: {self.val_ratio} æµ‹è¯•é›†: {self.test_ratio}")
        logger.info(f"çº¿ç¨‹æ± é…ç½® - æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.max_workers}")

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿çº¿ç¨‹æ± æ­£ç¡®å…³é—­"""
        if hasattr(self, 'thread_pool'):
            self.thread_pool.shutdown(wait=True)

    def filter_specified_labels(self, label_list: List[str], keep_mode: bool = True) -> Dict:
        """
        ç­›é€‰æŒ‡å®šæ ‡ç­¾çš„æ ‡æ³¨æ¡†
        
        Args:
            label_list: æ ‡ç­¾åˆ—è¡¨
            keep_mode: Trueè¡¨ç¤ºä¿ç•™label_listä¸­çš„æ ‡ç­¾ï¼ŒFalseè¡¨ç¤ºç§»é™¤label_listä¸­çš„æ ‡ç­¾
        
        Returns:
            dict: å¤„ç†ç»“æœç»Ÿè®¡
        """
        mode_desc = "ä¿ç•™" if keep_mode else "ç§»é™¤"
        logger.info(f"å¼€å§‹{mode_desc}æŒ‡å®šæ ‡ç­¾: {label_list}")
        
        # ä½¿ç”¨æŒ‡å®šçš„æ ‡æ³¨æ–‡ä»¶å¤¹
        annotations_dir = self.dataset_path / self.annotations_folder_name
        if not annotations_dir.exists():
            logger.error(f"æ ‡æ³¨æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {annotations_dir}")
            return {"success": False, "error": "æ ‡æ³¨æ–‡ä»¶å¤¹ä¸å­˜åœ¨"}
        
        removed_count = 0
        kept_count = 0
        processed_count = 0
        empty_files = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = self.dataset_path / f"{self.annotations_folder_name}_filtered"
        output_dir.mkdir(exist_ok=True)
        logger.info(f"ç­›é€‰ç»“æœå°†ä¿å­˜åˆ°: {output_dir}")
        
        xml_files = list(annotations_dir.glob("*.xml"))
        logger.info(f"å‘ç° {len(xml_files)} ä¸ªXMLæ–‡ä»¶éœ€è¦å¤„ç†")
        
        for xml_file in tqdm(xml_files, desc=f"{mode_desc}æ ‡ç­¾"):
            try:
                tree = ET.parse(xml_file)
                root = tree.getroot()
                
                # æ‰¾åˆ°éœ€è¦å¤„ç†çš„objectå…ƒç´ 
                objects_to_process = []
                for obj in root.findall('object'):
                    name_elem = obj.find('name')
                    if name_elem is not None:
                        label_name = name_elem.text
                        
                        if keep_mode:
                            # ä¿ç•™æ¨¡å¼ï¼šç§»é™¤ä¸åœ¨åˆ—è¡¨ä¸­çš„æ ‡ç­¾
                            if label_name not in label_list:
                                objects_to_process.append(obj)
                        else:
                            # ç§»é™¤æ¨¡å¼ï¼šç§»é™¤åœ¨åˆ—è¡¨ä¸­çš„æ ‡ç­¾
                            if label_name in label_list:
                                objects_to_process.append(obj)
                
                # å¤„ç†æ‰¾åˆ°çš„objectå…ƒç´ 
                for obj in objects_to_process:
                    root.remove(obj)
                    removed_count += 1
                
                # ç»Ÿè®¡ä¿ç•™çš„æ ‡æ³¨æ¡†
                remaining_objects = len(root.findall('object'))
                kept_count += remaining_objects
                
                # ä¿å­˜åˆ°è¾“å‡ºç›®å½•
                output_file = output_dir / xml_file.name
                
                if remaining_objects == 0:
                    # å¦‚æœæ²¡æœ‰å‰©ä½™æ ‡æ³¨æ¡†ï¼Œè®°å½•ä½†ä¸ä¿å­˜æ–‡ä»¶
                    empty_files.append(xml_file.name)
                    logger.debug(f"æ–‡ä»¶ {xml_file.name} ç­›é€‰åæ— æ ‡æ³¨æ¡†ï¼Œè·³è¿‡ä¿å­˜")
                else:
                    # ä¿æŒåŸæœ‰XMLæ ¼å¼
                    tree.write(output_file, encoding='utf-8', xml_declaration=True)
                
                processed_count += 1
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {xml_file} æ—¶å‡ºé”™: {e}")
        
        result = {
            "success": True,
            "mode": mode_desc,
            "processed_files": processed_count,
            "removed_annotations": removed_count,
            "kept_annotations": kept_count,
            "empty_files": len(empty_files),
            "output_dir": str(output_dir)
        }
        
        logger.info(f"æ ‡ç­¾ç­›é€‰å®Œæˆ:")
        logger.info(f"  æ¨¡å¼: {mode_desc}æ ‡ç­¾ {label_list}")
        logger.info(f"  å¤„ç†æ–‡ä»¶: {processed_count} ä¸ª")
        logger.info(f"  ç§»é™¤æ ‡æ³¨æ¡†: {removed_count} ä¸ª")
        logger.info(f"  ä¿ç•™æ ‡æ³¨æ¡†: {kept_count} ä¸ª")
        logger.info(f"  ç©ºæ–‡ä»¶æ•°: {len(empty_files)} ä¸ª")
        logger.info(f"  è¾“å‡ºç›®å½•: {output_dir}")
        
        return result

    def one_click_complete_conversion(self, skip_confirmation=False):
        """ä¸€é”®å®Œæˆè½¬æ¢å¹¶ä¿®å¤æ‰€æœ‰é—®é¢˜"""
        logger.info("="*80)
        logger.info("ğŸš€ å¼€å§‹ä¸€é”®å®Œæˆè½¬æ¢å¤„ç†ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰")
        logger.info("="*80)
        logger.info(f"æ•°æ®é›†åç§°: {self.dataset_name}")
        logger.info(f"æ•°æ®é›†è·¯å¾„: {self.dataset_path}")
        logger.info(f"æ ‡æ³¨æ–‡ä»¶å¤¹: {self.annotations_folder_name}")
        logger.info(f"çº¿ç¨‹æ± é…ç½®: {self.max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
        logger.info(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # æç¤ºç”¨æˆ·ç¡®è®¤
        print("\n" + "="*80)
        print("âš ï¸  è­¦å‘Šï¼šå³å°†å¼€å§‹å¤„ç†æ•°æ®é›†")
        print("="*80)
        print("ğŸ“‹ å¤„ç†å†…å®¹åŒ…æ‹¬ï¼š")
        print("   1. æ¸…æ´—å’Œä¿®æ­£XMLæ ‡æ³¨æ–‡ä»¶")
        print("   2. ä¿®æ­£å›¾ç‰‡å’ŒXMLå°ºå¯¸ä¸åŒ¹é…é—®é¢˜")
        print("   3. åˆ é™¤ç©ºæ ‡æ³¨å’Œæ— æ•ˆæ–‡ä»¶")
        print("   4. åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†")
        print("   5. è½¬æ¢ä¸ºCOCOæ ¼å¼")
        print("\nğŸ”¥ é‡è¦æé†’ï¼šè¯·ç¡®ä¿å·²å¤‡ä»½åŸå§‹æ•°æ®é›†ï¼")
        print("="*80)

        if not skip_confirmation:
            user_input = input("æ˜¯å¦ç»§ç»­å¤„ç†ï¼Ÿè¾“å…¥ Y ç»§ç»­ï¼ŒN å–æ¶ˆ: ").strip()
            if user_input.upper() != 'Y':
                print("âŒ æ“ä½œå·²å–æ¶ˆ")
                return {"success": False, "message": "ç”¨æˆ·å–æ¶ˆæ“ä½œ"}

        try:
            # åˆ›å»ºæ¸…æ´—åçš„è¾“å‡ºç›®å½•
            self.annotations_output_dir.mkdir(exist_ok=True)
            logger.info(f"åˆ›å»ºæ¸…æ´—è¾“å‡ºç›®å½•: {self.annotations_output_dir}")

            # æ­¥éª¤1: æ•°æ®é›†åŸºæœ¬éªŒè¯
            print("\nğŸ“‹ æ­¥éª¤1: æ•°æ®é›†åŸºæœ¬éªŒè¯...")
            logger.info("ğŸ“‹ æ­¥éª¤1: å¼€å§‹æ•°æ®éªŒè¯å’Œæ¸…æ´—")
            
            logger.info("ğŸ” éªŒè¯æ•°æ®é›†åŸºæœ¬ç»“æ„...")
            self._validate_basic_structure()
            logger.info("âœ… æ•°æ®é›†ç»“æ„éªŒè¯å®Œæˆ")
            
            logger.info("ğŸ”— å¼€å§‹å¹¶è¡ŒåŒ¹é…å›¾åƒå’Œæ ‡æ³¨æ–‡ä»¶...")
            self._match_files_parallel()
            logger.info("âœ… å¹¶è¡Œæ–‡ä»¶åŒ¹é…å®Œæˆ - æœ‰æ•ˆæ–‡ä»¶å¯¹: {len(self.valid_files)} ä¸ª")
            
            logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†ç©ºæ ‡æ³¨æ–‡ä»¶å¹¶æ¸…æ´—XML...")
            empty_count = self._remove_empty_annotations_and_clean()
            logger.info(f"âœ… XMLæ¸…æ´—å®Œæˆ - åˆ é™¤ç©ºæ ‡æ³¨: {empty_count} ä¸ª")
            
            # æ­¥éª¤2: æå–ç±»åˆ«ä¿¡æ¯
            logger.info("ğŸ·ï¸  å¼€å§‹æå–ç±»åˆ«ä¿¡æ¯...")
            self._extract_classes()
            logger.info("âœ… ç±»åˆ«ä¿¡æ¯æå–å®Œæˆ")
            
            # æ­¥éª¤3: æ£€æŸ¥å’Œä¿®æ­£å›¾åƒå°ºå¯¸
            print("\nğŸ“‹ æ­¥éª¤2: æ£€æŸ¥å’Œä¿®æ­£å›¾åƒå°ºå¯¸...")
            logger.info("ğŸ“‹ æ­¥éª¤2: å¼€å§‹æ£€æŸ¥å’Œä¿®æ­£å›¾åƒå°ºå¯¸")
            self.check_and_fix_image_dimensions()
            logger.info("âœ… å›¾åƒå°ºå¯¸æ£€æŸ¥å’Œä¿®æ­£å®Œæˆ")
            
            # æ­¥éª¤4: åˆ’åˆ†æ•°æ®é›†
            print("\nğŸ“‹ æ­¥éª¤3: åˆ’åˆ†æ•°æ®é›†...")
            logger.info("ğŸ“‹ æ­¥éª¤3: å¼€å§‹åˆ’åˆ†æ•°æ®é›†")
            self.split_dataset_optimized()
            logger.info("âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ")
            
            # æ­¥éª¤5: è½¬æ¢ä¸ºCOCOæ ¼å¼
            print("\nğŸ“‹ æ­¥éª¤4: è½¬æ¢ä¸ºCOCOæ ¼å¼...")
            logger.info("ğŸ“‹ æ­¥éª¤4: å¼€å§‹è½¬æ¢ä¸ºCOCOæ ¼å¼")
            self._convert_to_coco_train_val_only()
            logger.info("âœ… COCOæ ¼å¼è½¬æ¢å®Œæˆ")
            
            # å®Œæˆå¤„ç†
            print("\n" + "="*80)
            print("ğŸ‰ æ•°æ®é›†å¤„ç†å®Œæˆï¼")
            print("="*80)
            
            result = {
                "success": True,
                "dataset_name": self.dataset_name,
                "dataset_path": str(self.dataset_path),
                "annotations_folder": self.annotations_folder_name,
                "total_classes": len(self.classes),
                "classes": list(self.classes),
                "total_images": self.total_images,
                "total_annotations": self.total_annotations,
                "clean_output_dir": str(self.annotations_output_dir)
            }
            
            logger.info("ğŸ‰ ä¸€é”®è½¬æ¢å¤„ç†å®Œæˆï¼")
            logger.info(f"å¤„ç†ç»“æœ: {result}")
            
            return result
            
        except Exception as e:
            error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            print(f"\nâŒ {error_msg}")
            return {"success": False, "error": str(e)}

    def get_dataset_info(self):
        """è·å–æ•°æ®é›†åŸºæœ¬ä¿¡æ¯"""
        return {
            "dataset_name": self.dataset_name,
            "dataset_path": str(self.dataset_path),
            "annotations_folder": self.annotations_folder_name,
            "annotations_dir": str(self.annotations_dir),
            "images_dir": str(self.images_dir),
            "imagesets_dir": str(self.imagesets_dir),
            "clean_output_dir": str(self.annotations_output_dir),
            "train_ratio": self.train_ratio,
            "val_ratio": self.val_ratio,
            "test_ratio": self.test_ratio,
            "max_workers": self.max_workers
        }

    # è¿™é‡Œéœ€è¦åŒ…å«åŸæœ‰çš„æ‰€æœ‰å…¶ä»–æ–¹æ³•...
    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘åªå±•ç¤ºäº†å…³é”®çš„æ–°å¢å’Œä¿®æ”¹çš„æ–¹æ³•
    # å®é™…ä½¿ç”¨æ—¶éœ€è¦ä»åŸæ–‡ä»¶å¤åˆ¶æ‰€æœ‰å…¶ä»–æ–¹æ³•


if __name__ == "__main__":
    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    dataset_path = r"D:\WJL\project\BirdNest"
    
    try:
        # æµ‹è¯•è‡ªå®šä¹‰æ ‡æ³¨æ–‡ä»¶å¤¹
        voc_dataset = VOCDataset(
            dataset_path=dataset_path,
            annotations_folder_name="Annotations"  # å¯ä»¥è‡ªå®šä¹‰
        )
        
        print("æ•°æ®é›†ä¿¡æ¯:", voc_dataset.get_dataset_info())
        
        # æµ‹è¯•æ ‡ç­¾ç­›é€‰åŠŸèƒ½
        keep_labels = [100, 101, 102, 113, 140, 150, 153, 154, 155, 200, 201, 202, 203, 204, 205, 220, 221, 240]
        keep_labels_str = [str(label) for label in keep_labels]  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        
        print(f"\nå¼€å§‹ç­›é€‰æ ‡ç­¾ï¼Œä¿ç•™: {keep_labels}")
        result = voc_dataset.filter_specified_labels(keep_labels_str, keep_mode=True)
        print(f"ç­›é€‰ç»“æœ: {result}")
        
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")